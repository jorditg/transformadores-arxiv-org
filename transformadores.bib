@misc{imagenetclassificationleaderboard,
	title = {Top 1 Accuracy in ImageNet Image Classification},
	howpublished = {\url{https://paperswithcode.com/sota/image-classification-on-imagenet}},
	note = {Accessed: 2022-09-21}
}

@inproceedings{he2016deep,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={770--778},
	year={2016}
}

@article{phuong2022formal,
	title={Formal Algorithms for Transformers},
	author={Phuong, Mary and Hutter, Marcus},
	journal={arXiv preprint arXiv:2207.09238},
	year={2022}
}

@article{press2016using,
	title={Using the output embedding to improve language models},
	author={Press, Ofir and Wolf, Lior},
	journal={arXiv preprint arXiv:1608.05859},
	year={2016}
}

@article{gage1994new-BPE,
	title={A new algorithm for data compression},
	author={Gage, Philip},
	journal={C Users Journal},
	volume={12},
	number={2},
	pages={23--38},
	year={1994},
	publisher={McPherson, KS: R \& D Publications, c1987-1994.}
}


@article{bronstein2021geometric,
	title={Geometric deep learning: Grids, groups, graphs, geodesics, and gauges},
	author={Bronstein, Michael M and Bruna, Joan and Cohen, Taco and Veli{\v{c}}kovi{\'c}, Petar},
	journal={arXiv preprint arXiv:2104.13478},
	year={2021}
}

@article{xu2022multimodal,
	title={Multimodal Learning with Transformers: A Survey},
	author={Xu, Peng and Zhu, Xiatian and Clifton, David A},
	journal={arXiv preprint arXiv:2206.06488},
	year={2022}
}

@article{lu2019vilbert,
	title={Vilbert: Pretraining task-agnostic visiolinguistic representations for vision-and-language tasks},
	author={Lu, Jiasen and Batra, Dhruv and Parikh, Devi and Lee, Stefan},
	journal={Advances in neural information processing systems},
	volume={32},
	year={2019}
}

@inproceedings{sun2019videobert,
	title={Videobert: A joint model for video and language representation learning},
	author={Sun, Chen and Myers, Austin and Vondrick, Carl and Murphy, Kevin and Schmid, Cordelia},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={7464--7473},
	year={2019}
}

@article{akbari2021vatt,
	title={Vatt: Transformers for multimodal self-supervised learning from raw video, audio and text},
	author={Akbari, Hassan and Yuan, Liangzhe and Qian, Rui and Chuang, Wei-Hong and Chang, Shih-Fu and Cui, Yin and Gong, Boqing},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={24206--24221},
	year={2021}
}

@article{lin2021exploring,
	title={Exploring cross-video and cross-modality signals for weakly-supervised audio-visual video parsing},
	author={Lin, Yan-Bo and Tseng, Hung-Yu and Lee, Hsin-Ying and Lin, Yen-Yu and Yang, Ming-Hsuan},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={11449--11461},
	year={2021}
}

@article{nagrani2021attention,
	title={Attention bottlenecks for multimodal fusion},
	author={Nagrani, Arsha and Yang, Shan and Arnab, Anurag and Jansen, Aren and Schmid, Cordelia and Sun, Chen},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={14200--14213},
	year={2021}
}

@inproceedings{gavrilyuk2020actor,
	title={Actor-transformers for group activity recognition},
	author={Gavrilyuk, Kirill and Sanford, Ryan and Javan, Mehrsan and Snoek, Cees GM},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={839--848},
	year={2020}
}


@article{brown2020language,
	title={Language models are few-shot learners},
	author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
	journal={Advances in neural information processing systems},
	volume={33},
	pages={1877--1901},
	year={2020}
}

@article{kudo2018subword-unigram,
	title={Subword regularization: Improving neural network translation models with multiple subword candidates},
	author={Kudo, Taku},
	journal={arXiv preprint arXiv:1804.10959},
	year={2018}
}

@article{hornik1989multilayer,
	title={Multilayer feedforward networks are universal approximators},
	author={Hornik, Kurt and Stinchcombe, Maxwell and White, Halbert},
	journal={Neural networks},
	volume={2},
	number={5},
	pages={359--366},
	year={1989},
	publisher={Elsevier}
}

@article{lecun1989backpropagation,
	title={Backpropagation applied to handwritten zip code recognition},
	author={LeCun, Yann and Boser, Bernhard and Denker, John S and Henderson, Donnie and Howard, Richard E and Hubbard, Wayne and Jackel, Lawrence D},
	journal={Neural computation},
	volume={1},
	number={4},
	pages={541--551},
	year={1989},
	publisher={MIT Press}
}

@article{hochreiter1997long,
	title={Long short-term memory},
	author={Hochreiter, Sepp and Schmidhuber, J{\"u}rgen},
	journal={Neural computation},
	volume={9},
	number={8},
	pages={1735--1780},
	year={1997},
	publisher={MIT Press}
}

@article{mhaskar2016deep,
	title={Deep vs. shallow networks: An approximation theory perspective},
	author={Mhaskar, Hrushikesh N and Poggio, Tomaso},
	journal={Analysis and Applications},
	volume={14},
	number={06},
	pages={829--848},
	year={2016},
	publisher={World Scientific}
}

@phdthesis{ioannou2018structural,
	title={Structural priors in deep neural networks},
	author={Ioannou, Yani Andrew},
	year={2018},
	school={University of Cambridge}
}

@article{bahdanau2014neural,
	title={Neural machine translation by jointly learning to align and translate},
	author={Bahdanau, Dzmitry and Cho, Kyunghyun and Bengio, Yoshua},
	journal={arXiv preprint arXiv:1409.0473},
	year={2014}
}

@article{vaswani2017attention,
	title={Attention is all you need},
	author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
	journal={Advances in neural information processing systems},
	volume={30},
	year={2017}
}


@misc{explainedonline2021attention,
	title={	Multi-head attention mechanism: “queries”, “keys”, and “values,” over and over again },
	year=2021,
	howpublished = "\url{https://data-science-blog.com/blog/2021/04/07/multi-head-attention-mechanism/ https://theaisummer.com/self-attention/"}
}

@misc{colahlstms,
	title={	Understanding LSTMs },
	year=2015,
	howpublished = "\url{https://colah.github.io/posts/2015-08-Understanding-LSTMs/ (accedido en julio de 2022)"}
}


@article{liu2021survey,
	title={A survey of visual transformers},
	author={Liu, Yang and Zhang, Yao and Wang, Yixin and Hou, Feng and Yuan, Jin and Tian, Jiang and Zhang, Yang and Shi, Zhongchao and Fan, Jianping and He, Zhiqiang},
	journal={arXiv preprint arXiv:2111.06091},
	year={2021}
}


@article{wu2020visual,
	title={Visual transformers: Token-based image representation and processing for computer vision},
	author={Wu, Bichen and Xu, Chenfeng and Dai, Xiaoliang and Wan, Alvin and Zhang, Peizhao and Yan, Zhicheng and Tomizuka, Masayoshi and Gonzalez, Joseph and Keutzer, Kurt and Vajda, Peter},
	journal={arXiv preprint arXiv:2006.03677},
	year={2020}
}

@inproceedings{touvron2021training,
	title={Training data-efficient image transformers \& distillation through attention},
	author={Touvron, Hugo and Cord, Matthieu and Douze, Matthijs and Massa, Francisco and Sablayrolles, Alexandre and J{\'e}gou, Herv{\'e}},
	booktitle={International Conference on Machine Learning},
	pages={10347--10357},
	year={2021},
	organization={PMLR}
}

@article{dosovitskiy2020image,
	title={An image is worth 16x16 words: Transformers for image recognition at scale},
	author={Dosovitskiy, Alexey and Beyer, Lucas and Kolesnikov, Alexander and Weissenborn, Dirk and Zhai, Xiaohua and Unterthiner, Thomas and Dehghani, Mostafa and Minderer, Matthias and Heigold, Georg and Gelly, Sylvain and others},
	journal={arXiv preprint arXiv:2010.11929},
	year={2020}
}

@inproceedings{yuan2021tokens,
	title={Tokens-to-token vit: Training vision transformers from scratch on imagenet},
	author={Yuan, Li and Chen, Yunpeng and Wang, Tao and Yu, Weihao and Shi, Yujun and Jiang, Zi-Hang and Tay, Francis EH and Feng, Jiashi and Yan, Shuicheng},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={558--567},
	year={2021}
}

@inproceedings{wang2021pyramid,
	title={Pyramid vision transformer: A versatile backbone for dense prediction without convolutions},
	author={Wang, Wenhai and Xie, Enze and Li, Xiang and Fan, Deng-Ping and Song, Kaitao and Liang, Ding and Lu, Tong and Luo, Ping and Shao, Ling},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={568--578},
	year={2021}
}


@article{zhu2020deformable,
	title={Deformable detr: Deformable transformers for end-to-end object detection},
	author={Zhu, Xizhou and Su, Weijie and Lu, Lewei and Li, Bin and Wang, Xiaogang and Dai, Jifeng},
	journal={arXiv preprint arXiv:2010.04159},
	year={2020}
}

@inproceedings{zheng2021rethinking,
	title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
	author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={6881--6890},
	year={2021}
}

@article{kumar2021colorization,
	title={Colorization transformer},
	author={Kumar, Manoj and Weissenborn, Dirk and Kalchbrenner, Nal},
	journal={arXiv preprint arXiv:2102.04432},
	year={2021}
}

@inproceedings{chen2021pre,
	title={Pre-trained image processing transformer},
	author={Chen, Hanting and Wang, Yunhe and Guo, Tianyu and Xu, Chang and Deng, Yiping and Liu, Zhenhua and Ma, Siwei and Xu, Chunjing and Xu, Chao and Gao, Wen},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={12299--12310},
	year={2021}
}

@inproceedings{arnab2021vivit,
	title={Vivit: A video vision transformer},
	author={Arnab, Anurag and Dehghani, Mostafa and Heigold, Georg and Sun, Chen and Lu{\v{c}}i{\'c}, Mario and Schmid, Cordelia},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={6836--6846},
	year={2021}
}

@article{tuli2021convolutional,
	title={Are Convolutional Neural Networks or Transformers more like human vision?},
	author={Tuli, Shikhar and Dasgupta, Ishita and Grant, Erin and Griffiths, Thomas L},
	journal={arXiv preprint arXiv:2105.07197},
	year={2021}
}

@inproceedings{word2vec,
	author = {Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff},
	booktitle = {Advances in Neural Information Processing Systems},
	editor = {C.J. Burges and L. Bottou and M. Welling and Z. Ghahramani and K.Q. Weinberger},
	pages = {},
	publisher = {Curran Associates, Inc.},
	title = {Distributed Representations of Words and Phrases and their Compositionality},
	url = {https://proceedings.neurips.cc/paper/2013/file/9aa42b31882ec039965f3c4923ce901b-Paper.pdf},
	volume = {26},
	year = {2013}
}

@inproceedings{pennington2014glove,
	title={Glove: Global vectors for word representation},
	author={Pennington, Jeffrey and Socher, Richard and Manning, Christopher D},
	booktitle={Proceedings of the 2014 conference on empirical methods in natural language processing (EMNLP)},
	pages={1532--1543},
	year={2014}
}

@article{joulin2016fasttext,
	title={FastText.zip: Compressing text classification models},
	author={Joulin, Armand and Grave, Edouard and Bojanowski, Piotr and Douze, Matthijs and J{\'e}gou, H{\'e}rve and Mikolov, Tomas},
	journal={arXiv preprint arXiv:1612.03651},
	year={2016}
}

@article{howard2018universal,
	title={Universal language model fine-tuning for text classification},
	author={Howard, Jeremy and Ruder, Sebastian},
	journal={arXiv preprint arXiv:1801.06146},
	year={2018}
}

@article{radford2018improving,
	title={Improving language understanding with unsupervised learning},
	author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya},
	year={2018},
	publisher={Technical report, OpenAI}
}

@article{radford2019language,
	title={Language models are unsupervised multitask learners},
	author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
	journal={OpenAI blog},
	volume={1},
	number={8},
	pages={9},
	year={2019}
}

@article{devlin2018bert,
	title={Bert: Pre-training of deep bidirectional transformers for language understanding},
	author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
	journal={arXiv preprint arXiv:1810.04805},
	year={2018}
}

@article{liu2019roberta,
	title={Roberta: A robustly optimized bert pretraining approach},
	author={Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin},
	journal={arXiv preprint arXiv:1907.11692},
	year={2019}
}

@article{raffel2020exploring,
	title={Exploring the limits of transfer learning with a unified text-to-text transformer.},
	author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J and others},
	journal={J. Mach. Learn. Res.},
	volume={21},
	number={140},
	pages={1--67},
	year={2020}
}

@article{hinton2015distilling,
	title={Distilling the knowledge in a neural network},
	author={Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff and others},
	journal={arXiv preprint arXiv:1503.02531},
	volume={2},
	number={7},
	year={2015}
}

@article{abnar2020transferring,
	title={Transferring inductive biases through knowledge distillation},
	author={Abnar, Samira and Dehghani, Mostafa and Zuidema, Willem},
	journal={arXiv preprint arXiv:2006.00555},
	year={2020}
}


@article{picek2022automatic,
	title={Automatic fungi recognition: Deep learning meets mycology},
	author={Picek, Luk{\'a}{\v{s}} and {\v{S}}ulc, Milan and Matas, Ji{\v{r}}{\'\i} and Heilmann-Clausen, Jacob and Jeppesen, Thomas S and Lind, Emil},
	journal={Sensors},
	volume={22},
	number={2},
	pages={633},
	year={2022},
	publisher={MDPI}
}

@article{ding2022davit,
	title={DaViT: Dual Attention Vision Transformers},
	author={Ding, Mingyu and Xiao, Bin and Codella, Noel and Luo, Ping and Wang, Jingdong and Yuan, Lu},
	journal={arXiv preprint arXiv:2204.03645},
	year={2022}
}

@inproceedings{pham2021meta,
	title={Meta pseudo labels},
	author={Pham, Hieu and Dai, Zihang and Xie, Qizhe and Le, Quoc V},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={11557--11568},
	year={2021}
}

@inproceedings{carion2020end,
	title={End-to-end object detection with transformers},
	author={Carion, Nicolas and Massa, Francisco and Synnaeve, Gabriel and Usunier, Nicolas and Kirillov, Alexander and Zagoruyko, Sergey},
	booktitle={European conference on computer vision},
	pages={213--229},
	year={2020},
	organization={Springer}
}

@inproceedings{lin2017focal,
	title={Focal loss for dense object detection},
	author={Lin, Tsung-Yi and Goyal, Priya and Girshick, Ross and He, Kaiming and Doll{\'a}r, Piotr},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2980--2988},
	year={2017}
}

@inproceedings{he2017mask,
	title={Mask r-cnn},
	author={He, Kaiming and Gkioxari, Georgia and Doll{\'a}r, Piotr and Girshick, Ross},
	booktitle={Proceedings of the IEEE international conference on computer vision},
	pages={2961--2969},
	year={2017}
}

@article{chen2021pix2seq,
	title={Pix2seq: A language modeling framework for object detection},
	author={Chen, Ting and Saxena, Saurabh and Li, Lala and Fleet, David J and Hinton, Geoffrey},
	journal={arXiv preprint arXiv:2109.10852},
	year={2021}
}

@inproceedings{stewart2016end,
	title={End-to-end people detection in crowded scenes},
	author={Stewart, Russell and Andriluka, Mykhaylo and Ng, Andrew Y},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2325--2333},
	year={2016}
}

@inproceedings{zheng2021rethinking,
	title={Rethinking semantic segmentation from a sequence-to-sequence perspective with transformers},
	author={Zheng, Sixiao and Lu, Jiachen and Zhao, Hengshuang and Zhu, Xiatian and Luo, Zekun and Wang, Yabiao and Fu, Yanwei and Feng, Jianfeng and Xiang, Tao and Torr, Philip HS and others},
	booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
	pages={6881--6890},
	year={2021}
}

@article{cheng2021per,
	title={Per-pixel classification is not all you need for semantic segmentation},
	author={Cheng, Bowen and Schwing, Alex and Kirillov, Alexander},
	journal={Advances in Neural Information Processing Systems},
	volume={34},
	pages={17864--17875},
	year={2021}
}

@inproceedings{cheng2022masked,
	title={Masked-attention mask transformer for universal image segmentation},
	author={Cheng, Bowen and Misra, Ishan and Schwing, Alexander G and Kirillov, Alexander and Girdhar, Rohit},
	booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
	pages={1290--1299},
	year={2022}
}

@inproceedings{lin2017feature,
	title={Feature pyramid networks for object detection},
	author={Lin, Tsung-Yi and Doll{\'a}r, Piotr and Girshick, Ross and He, Kaiming and Hariharan, Bharath and Belongie, Serge},
	booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
	pages={2117--2125},
	year={2017}
}

@inproceedings{ronneberger2015u,
	title={U-net: Convolutional networks for biomedical image segmentation},
	author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
	booktitle={International Conference on Medical image computing and computer-assisted intervention},
	pages={234--241},
	year={2015},
	organization={Springer}
}

@book{bracewell1986fourier,
	title={The Fourier transform and its applications},
	author={Bracewell, Ronald Newbold and Bracewell, Ronald N},
	volume={31999},
	year={1986},
	publisher={McGraw-Hill New York}
}

@incollection{nussbaumer1981fast,
	title={The fast Fourier transform},
	author={Nussbaumer, Henri J},
	booktitle={Fast Fourier Transform and Convolution Algorithms},
	pages={80--111},
	year={1981},
	publisher={Springer}
}

@article{stevens1937scale,
	title={A scale for the measurement of the psychological magnitude pitch},
	author={Stevens, Stanley Smith and Volkmann, John and Newman, Edwin Broomell},
	journal={The journal of the acoustical society of america},
	volume={8},
	number={3},
	pages={185--190},
	year={1937},
	publisher={Acoustical Society of America}
}

@article{radfordrobust,
	title={Robust Speech Recognition via Large-Scale Weak Supervision},
	author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya}
}

@article{baevski2020wav2vec,
	title={wav2vec 2.0: A framework for self-supervised learning of speech representations},
	author={Baevski, Alexei and Zhou, Yuhao and Mohamed, Abdelrahman and Auli, Michael},
	journal={Advances in Neural Information Processing Systems},
	volume={33},
	pages={12449--12460},
	year={2020}
}

@inproceedings{subakan2021attention,
	title={Attention is all you need in speech separation},
	author={Subakan, Cem and Ravanelli, Mirco and Cornell, Samuele and Bronzi, Mirko and Zhong, Jianyuan},
	booktitle={ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
	pages={21--25},
	year={2021},
	organization={IEEE}
}

@article{reed2022generalist,
	title={A generalist agent},
	author={Reed, Scott and Zolna, Konrad and Parisotto, Emilio and Colmenarejo, Sergio Gomez and Novikov, Alexander and Barth-Maron, Gabriel and Gimenez, Mai and Sulsky, Yury and Kay, Jackie and Springenberg, Jost Tobias and others},
	journal={arXiv preprint arXiv:2205.06175},
	year={2022}
}

@article{rasmy2021med,
	title={Med-BERT: pretrained contextualized embeddings on large-scale structured electronic health records for disease prediction},
	author={Rasmy, Laila and Xiang, Yang and Xie, Ziqian and Tao, Cui and Zhi, Degui},
	journal={NPJ digital medicine},
	volume={4},
	number={1},
	pages={1--13},
	year={2021},
	publisher={Nature Publishing Group}
}

@article{kiela2019supervised,
	title={Supervised multimodal bitransformers for classifying images and text},
	author={Kiela, Douwe and Bhooshan, Suvrat and Firooz, Hamed and Perez, Ethan and Testuggine, Davide},
	journal={arXiv preprint arXiv:1909.02950},
	year={2019}
}

@article{weng2021semi,
	title={Semi-supervised vision transformers},
	author={Weng, Zejia and Yang, Xitong and Li, Ang and Wu, Zuxuan and Jiang, Yu-Gang},
	journal={arXiv preprint arXiv:2111.11067},
	year={2021}
}

@inproceedings{gao2021fast,
	title={Fast convergence of detr with spatially modulated co-attention},
	author={Gao, Peng and Zheng, Minghang and Wang, Xiaogang and Dai, Jifeng and Li, Hongsheng},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={3621--3630},
	year={2021}
}

@inproceedings{meng2021conditional,
	title={Conditional detr for fast training convergence},
	author={Meng, Depu and Chen, Xiaokang and Fan, Zejia and Zeng, Gang and Li, Houqiang and Yuan, Yuhui and Sun, Lei and Wang, Jingdong},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={3651--3660},
	year={2021}
}

@inproceedings{wang2022anchor,
	title={Anchor detr: Query design for transformer-based detector},
	author={Wang, Yingming and Zhang, Xiangyu and Yang, Tong and Sun, Jian},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={36},
	number={3},
	pages={2567--2575},
	year={2022}
}

@article{liu2022dab,
	title={DAB-DETR: Dynamic anchor boxes are better queries for DETR},
	author={Liu, Shilong and Li, Feng and Zhang, Hao and Yang, Xiao and Qi, Xianbiao and Su, Hang and Zhu, Jun and Zhang, Lei},
	journal={arXiv preprint arXiv:2201.12329},
	year={2022}
}

@article{yao2021efficient,
	title={Efficient detr: improving end-to-end object detector with dense prior},
	author={Yao, Zhuyu and Ai, Jiangbo and Li, Boxun and Zhang, Chi},
	journal={arXiv preprint arXiv:2104.01318},
	year={2021}
}

@inproceedings{dai2021dynamic,
	title={Dynamic detr: End-to-end object detection with dynamic attention},
	author={Dai, Xiyang and Chen, Yinpeng and Yang, Jianwei and Zhang, Pengchuan and Yuan, Lu and Zhang, Lei},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={2988--2997},
	year={2021}
}

@article{xu2021deepchange,
	title={Deepchange: A large long-term person re-identification benchmark with clothes change},
	author={Xu, Peng and Zhu, Xiatian},
	journal={arXiv e-prints},
	pages={arXiv--2105},
	year={2021}
}

@article{guo2020graphcodebert,
	title={Graphcodebert: Pre-training code representations with data flow},
	author={Guo, Daya and Ren, Shuo and Lu, Shuai and Feng, Zhangyin and Tang, Duyu and Liu, Shujie and Zhou, Long and Duan, Nan and Svyatkovskiy, Alexey and Fu, Shengyu and others},
	journal={arXiv preprint arXiv:2009.08366},
	year={2020}
}

@article{shi2022learning,
	title={Learning audio-visual speech representation by masked multimodal cluster prediction},
	author={Shi, Bowen and Hsu, Wei-Ning and Lakhotia, Kushal and Mohamed, Abdelrahman},
	journal={arXiv preprint arXiv:2201.02184},
	year={2022}
}

@inproceedings{zheng2021fused,
	title={Fused acoustic and text encoding for multimodal bilingual pretraining and speech translation},
	author={Zheng, Renjie and Chen, Junkun and Ma, Mingbo and Huang, Liang},
	booktitle={International Conference on Machine Learning},
	pages={12736--12746},
	year={2021},
	organization={PMLR}
}

@inproceedings{li2021ai,
	title={Ai choreographer: Music conditioned 3d dance generation with aist++},
	author={Li, Ruilong and Yang, Shan and Ross, David A and Kanazawa, Angjoo},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={13401--13412},
	year={2021}
}

@article{lin2020interbert,
	title={Interbert: Vision-and-language interaction for multi-modal pretraining},
	author={Lin, Junyang and Yang, An and Zhang, Yichang and Liu, Jie and Zhou, Jingren and Yang, Hongxia},
	journal={arXiv preprint arXiv:2003.13198},
	year={2020}
}

@inproceedings{yun2021pano,
	title={Pano-avqa: Grounded audio-visual question answering on 360deg videos},
	author={Yun, Heeseung and Yu, Youngjae and Yang, Wonsuk and Lee, Kangil and Kim, Gunhee},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={2031--2041},
	year={2021}
}

@inproceedings{hasan2021humor,
	title={Humor knowledge enriched transformer for understanding multimodal humor},
	author={Hasan, Md Kamrul and Lee, Sangwu and Rahman, Wasifur and Zadeh, Amir and Mihalcea, Rada and Morency, Louis-Philippe and Hoque, Ehsan},
	booktitle={Proceedings of the AAAI Conference on Artificial Intelligence},
	volume={35},
	number={14},
	pages={12972--12980},
	year={2021}
}

@inproceedings{zhan2021product1m,
	title={Product1m: Towards weakly supervised instance-level product retrieval via cross-modal pretraining},
	author={Zhan, Xunlin and Wu, Yangxin and Dong, Xiao and Wei, Yunchao and Lu, Minlong and Zhang, Yichi and Xu, Hang and Liang, Xiaodan},
	booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
	pages={11782--11791},
	year={2021}
}

@inproceedings{tsai2019multimodal,
	title={Multimodal transformer for unaligned multimodal language sequences},
	author={Tsai, Yao-Hung Hubert and Bai, Shaojie and Liang, Paul Pu and Kolter, J Zico and Morency, Louis-Philippe and Salakhutdinov, Ruslan},
	booktitle={Proceedings of the conference. Association for Computational Linguistics. Meeting},
	volume={2019},
	pages={6558},
	year={2019},
	organization={NIH Public Access}
}

